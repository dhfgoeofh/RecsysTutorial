{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeongBeomLEE/RecsysTutorial/blob/main/BPR/BPR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qC4xR-8b9V3V"
      },
      "source": [
        "- GMF를 가지고 비교\n",
        "- 메트릭은 NDCG, HIT 사용\n",
        "- 동일한 Weigh, 배치마다 동일한 데이터셋으로 비교"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {
        "id": "dU4Rk5s_-sJV"
      },
      "outputs": [],
      "source": [
        "# !pip install python-box"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {
        "id": "7SbA1rBV8dMW"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import warnings\n",
        "from tqdm import tqdm\n",
        "\n",
        "from box import Box\n",
        "\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "data_dir = '../Data/MovieLens/'\n",
        "model_dir = '../Model/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {
        "id": "G6mDY5ic8S-_"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x20cb3f887d0>"
            ]
          },
          "execution_count": 195,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "seed = 22\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tj9zZZquHqKK"
      },
      "source": [
        "# 학습 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {
        "id": "Ts-KDn8V8r-k"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "    'top_k' : 10,\n",
        "    'epochs' : 50,\n",
        "    'lr' : 1e-03,\n",
        "    'batch_size' : 256,\n",
        "\n",
        "    'num_factor' :64,\n",
        "    \"reg\" : 1e-5,\n",
        "    'neg_samples' : 3,\n",
        "}\n",
        "\n",
        "config = Box(config)\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcHWD3OVHsyw"
      },
      "source": [
        "# 데이터셋"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {
        "id": "Ldv0nAnn-h-L"
      },
      "outputs": [],
      "source": [
        "class MakeDataset():\n",
        "    def __init__(self, config, df : pd.DataFrame):\n",
        "        self.config = config\n",
        "        self.df = df\n",
        "        self.user_encoder, self.user_decoder, self.item_encoder, self.item_decoder = self.get_encoder_decoder()\n",
        "        self.num_users = len(self.user_encoder)\n",
        "        self.num_items = len(self.item_encoder)\n",
        "        self.all_items = [i for i in range(self.num_items)]\n",
        "\n",
        "        self.df['userId'] = self.df['userId'].apply(lambda x : self.user_encoder[x])\n",
        "        self.df['movieId'] = self.df['movieId'].apply(lambda x : self.item_encoder[x])\n",
        "        self.user_neg_candidate = self.get_user_neg_candidate()\n",
        "\n",
        "        self.train_set_user, self.train_set_item, self.train_set_target, self.test_set_user, self.test_set_item, self.test_set_target = self.train_test_data_split()\n",
        "\n",
        "    def train_test_data_split(self):\n",
        "\n",
        "        user_id_li = self.df['userId'].unique()\n",
        "\n",
        "        train_set_item = []\n",
        "        train_set_user = []\n",
        "        train_set_target = []\n",
        "\n",
        "        test_set_item = []\n",
        "        test_set_user = []\n",
        "        test_set_target = []\n",
        "\n",
        "        for user_id in user_id_li:\n",
        "            user_df = self.df[self.df['userId'] == user_id].sort_values('timestamp')\n",
        "            movieId_li = user_df['movieId'].tolist()\n",
        "            \n",
        "            train_item = movieId_li[:-1]\n",
        "            train_user = [user_id] * len(train_item)\n",
        "            train_target = [1] * len(train_item)\n",
        "\n",
        "            test_item = [movieId_li[-1]] + np.random.choice(self.user_neg_candidate[user_id], 99, replace = False).tolist()\n",
        "            test_user = [user_id] * len(test_item)\n",
        "            test_target = [1] + [0] * (len(test_item) - 1)\n",
        "\n",
        "            train_set_item += train_item\n",
        "            train_set_user += train_user\n",
        "            train_set_target += train_target\n",
        "\n",
        "            test_set_item += test_item\n",
        "            test_set_user += test_user\n",
        "            test_set_target += test_target\n",
        "\n",
        "        return train_set_user, train_set_item, train_set_target, test_set_user, test_set_item, test_set_target\n",
        "\n",
        "    def get_neg_samples(self, n : int, user_id_li):\n",
        "        neg_samples_user = []\n",
        "        neg_samples_item = []\n",
        "        for u in user_id_li:\n",
        "            u_neg_candidate = self.user_neg_candidate[u]\n",
        "            for _ in range(n):\n",
        "                neg_samples_item.append(u_neg_candidate[np.random.randint(len(u_neg_candidate))])\n",
        "                neg_samples_user.append(u)\n",
        "\n",
        "        return neg_samples_user, neg_samples_item\n",
        "\n",
        "    def get_user_neg_candidate(self):\n",
        "        user_candidate = {}\n",
        "        for user_id in self.df['userId'].unique():\n",
        "            movieId_li = self.df[self.df['userId'] == user_id]['movieId'].tolist()\n",
        "            movieId_li = [movieId for movieId in movieId_li]\n",
        "            user_candidate[user_id] = list(set(self.all_items) - set(movieId_li))\n",
        "        \n",
        "        return user_candidate\n",
        "\n",
        "    def get_encoder_decoder(self):\n",
        "        user_encoder, user_decoder = {}, {}\n",
        "        for idx, user_id in enumerate(self.df['userId'].unique()):\n",
        "            user_encoder[user_id] = idx\n",
        "            user_decoder[idx] = user_id\n",
        "\n",
        "        item_encoder, item_decoder = {}, {}\n",
        "        for idx, item_id in enumerate(self.df['movieId'].unique()):\n",
        "            item_encoder[item_id] = idx\n",
        "            item_decoder[idx] = item_id\n",
        "        \n",
        "        return user_encoder, user_decoder, item_encoder, item_decoder\n",
        "    \n",
        "    def get_data(self, train : bool = True):\n",
        "        if train: return self.train_set_user, self.train_set_item, self.train_set_target\n",
        "        else: return self.test_set_user, self.test_set_item, self.test_set_target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "metadata": {
        "id": "W-9e--KXHMhb"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, set_user : list, set_item : list, set_target : list):\n",
        "        self.set_user = set_user\n",
        "        self.set_item = set_item\n",
        "        self.set_target = set_target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.set_user)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        user = self.set_user[idx]\n",
        "        item = self.set_item[idx]\n",
        "        target = self.set_target[idx]\n",
        "\n",
        "        return user, item, target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-bgIRfmHy6O"
      },
      "source": [
        "# 모델"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {
        "id": "mJzXQp1aHzk7"
      },
      "outputs": [],
      "source": [
        "class GMF(nn.Module):\n",
        "    def __init__(self, num_user, num_item, num_factor):\n",
        "        super(GMF, self).__init__()\n",
        "        self.user_emb = nn.Embedding(num_user, num_factor)\n",
        "        self.item_emb = nn.Embedding(num_item, num_factor)\n",
        "        \n",
        "        self.predict_layer = nn.Sequential(\n",
        "            nn.Linear(num_factor, 1, bias = False)\n",
        "        )\n",
        "\n",
        "        self._init_weight_()\n",
        "    \n",
        "    def _init_weight_(self):\n",
        "        nn.init.normal_(self.user_emb.weight, std=0.01)\n",
        "        nn.init.normal_(self.item_emb.weight, std=0.01)\n",
        "        for m in self.predict_layer:\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.kaiming_uniform_(m.weight, a=1, nonlinearity=\"sigmoid\")\n",
        "    \n",
        "    def forward(self, user, item):\n",
        "        user_emb = self.user_emb(user)\n",
        "        item_emb = self.item_emb(item)\n",
        "        \n",
        "        output = self.predict_layer(user_emb * item_emb)\n",
        "\n",
        "        return output.view(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # 수정 버전\n",
        "# class GMF(nn.Module):\n",
        "#     def __init__(self, num_user, num_item, num_factor):\n",
        "#         super(GMF, self).__init__()\n",
        "#         self.user_emb = nn.Embedding(num_user, 4*num_factor)\n",
        "#         self.item_emb = nn.Embedding(num_item, num_factor)\n",
        "\n",
        "#         self.fn_layer = nn.Sequential(\n",
        "#             nn.Linear(5*num_factor, num_factor, bias=False)\n",
        "#         )\n",
        "\n",
        "#         self.predict_layer = nn.Sequential(\n",
        "#             nn.Linear(num_factor, 1, bias = False)\n",
        "#         )\n",
        "\n",
        "#         self._init_weight_()\n",
        "    \n",
        "#     def _init_weight_(self):\n",
        "#         nn.init.normal_(self.user_emb.weight, std=0.01)\n",
        "#         nn.init.normal_(self.item_emb.weight, std=0.01)\n",
        "#         for m in self.predict_layer:\n",
        "#             if isinstance(m, nn.Linear):\n",
        "#                 nn.init.kaiming_uniform_(m.weight, a=1, nonlinearity=\"sigmoid\")\n",
        "    \n",
        "#     def forward(self, user, item):\n",
        "#         user_emb = self.user_emb(user)\n",
        "#         item_emb = self.item_emb(item)\n",
        "#         # print('total user emb:', self.user_emb)\n",
        "#         # print('total item emb:', self.item_emb)\n",
        "\n",
        "#         # print('user emb:', user_emb.shape)\n",
        "#         # print('item emb:', item_emb.shape)\n",
        "        \n",
        "#         # p_u' 계산\n",
        "#         concatenated_emb = torch.concatenate([user_emb, item_emb], dim=1)\n",
        "#         mutual_user_emb = self.fn_layer(concatenated_emb)\n",
        "\n",
        "#         output = self.predict_layer(mutual_user_emb * item_emb)\n",
        "\n",
        "#         return output.view(-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNYhN5yRIjB5"
      },
      "source": [
        "# 학습 함수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {
        "id": "HMlxwn8xIkr5"
      },
      "outputs": [],
      "source": [
        "def hit(target_item, pred_items):\n",
        "    if target_item in pred_items:\n",
        "        return 1\n",
        "    return 0\n",
        "\n",
        "def ndcg(target_item, pred_items):\n",
        "    if target_item in pred_items:\n",
        "        idx = pred_items.index(target_item)\n",
        "        # 초기 인덱스가 0이기 때문에 +2 함\n",
        "        return np.reciprocal(np.log2(idx + 2))\n",
        "    return 0\n",
        "\n",
        "def metrics(model, test_loader, top_k):\n",
        "    model.eval()\n",
        "    HR, NDCG = [], []\n",
        "    with torch.no_grad():\n",
        "        for user, item, _ in test_loader:\n",
        "            user = user.to(device)\n",
        "            item = item.to(device)\n",
        "\n",
        "            predictions = model(user, item)\n",
        "            # 가장 높은 top_k개 선택\n",
        "            _, indices = torch.topk(predictions, top_k)\n",
        "            # 해당 상품 index 선택\n",
        "            recommends = torch.take(item, indices).cpu().numpy().tolist()\n",
        "            # 정답값 선택\n",
        "            target_item = item[0].item()\n",
        "            HR.append(hit(target_item, recommends))\n",
        "            NDCG.append(ndcg(target_item, recommends))\n",
        "\n",
        "    return np.mean(HR), np.mean(NDCG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {
        "id": "F3PKzgFAOxll"
      },
      "outputs": [],
      "source": [
        "class BPR_Loss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BPR_Loss, self).__init__()\n",
        "    \n",
        "    def forward(self, pos, neg):\n",
        "        bpr_loss = -torch.mean(torch.log(torch.sigmoid(pos - neg)))\n",
        "        return bpr_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXt5O3vgIgqc"
      },
      "source": [
        "# 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {
        "id": "nmChH4jvIJoj"
      },
      "outputs": [],
      "source": [
        "ratings_df = pd.read_csv(data_dir + 'ratings.csv')\n",
        "\n",
        "dataset = MakeDataset(config = config, df = ratings_df)\n",
        "\n",
        "train_set_user, train_set_item, train_set_target = dataset.get_data(train = True)\n",
        "train_dataset = CustomDataset(set_user = train_set_user, set_item = train_set_item, set_target = train_set_target)\n",
        "train_loader = DataLoader(train_dataset, batch_size = config.batch_size, shuffle = True, drop_last = False)\n",
        "\n",
        "test_set_user, test_set_item, test_set_target = dataset.get_data(train = False)\n",
        "test_dataset = CustomDataset(set_user = test_set_user, set_item = test_set_item, set_target = test_set_target)\n",
        "test_loader = DataLoader(test_dataset, batch_size = 100, shuffle = False, drop_last = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qMDn76jSDDL",
        "outputId": "2c9d3463-b59d-468e-b2ef-4b31da994780"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[EPOCH: 50]\n",
            "Non-BPR-GMF Train Loss: 0.0237, HR: 0.7049, NDCG: 0.4754\n",
            "BPR-GMF Train Loss: 0.0072, HR: 0.7213, NDCG: 0.4724\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import copy\n",
        "# 동일한 Weigh에서 초기화 시키기 위해서 copy 사용\n",
        "\n",
        "gmf = GMF(num_user = dataset.num_users, num_item = dataset.num_items, num_factor = config.num_factor)\n",
        "model = copy.deepcopy(gmf).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = config.lr)\n",
        "loss_func = nn.BCELoss()\n",
        "\n",
        "bpr_model = copy.deepcopy(gmf).to(device)\n",
        "bpr_optimizer = torch.optim.Adam(bpr_model.parameters(), lr = config.lr)\n",
        "bpr_loss_func = BPR_Loss()\n",
        "\n",
        "non_bpr_model_loss_list = []\n",
        "non_bpr_model_hr_list = []\n",
        "non_bpr_model_ndcg_list = []\n",
        "\n",
        "bpr_model_loss_list = []\n",
        "bpr_model_hr_list = []\n",
        "bpr_model_ndcg_list = []\n",
        "\n",
        "result_hr_list = []\n",
        "result_ndcg_list = []\n",
        "\n",
        "result_non_bpr_hr_list = []\n",
        "result_non_bpr_ndcg_list = []\n",
        "\n",
        "best_metric = 0\n",
        "bpr_best_metric = 0\n",
        "\n",
        "for epoch in range(1, config.epochs + 1):\n",
        "    # 학습\n",
        "    model.train()\n",
        "    bpr_model.train()\n",
        "\n",
        "    train_loss = 0\n",
        "    bpr_train_loss = 0\n",
        "\n",
        "    for user, item, target in train_loader:\n",
        "        # neg_sampling\n",
        "        neg_user, neg_item = dataset.get_neg_samples(n = config.neg_samples, user_id_li = user.numpy().tolist())\n",
        "        neg_target = [0] * len(neg_item)\n",
        "\n",
        "        user, item, target = user.to(device), item.to(device), target.to(device).float()\n",
        "        neg_user, neg_item, neg_target = torch.tensor(neg_user).to(device), torch.tensor(neg_item).to(device), torch.tensor(neg_target).to(device).float()\n",
        "\n",
        "        all_user = torch.concat([user, torch.tensor(neg_user)])\n",
        "        all_item = torch.concat([item, torch.tensor(neg_item)])\n",
        "        all_target = torch.concat([target, torch.tensor(neg_target)])\n",
        "\n",
        "        # BPR X 모델 학습\n",
        "        optimizer.zero_grad()\n",
        "        output = model(all_user, all_item)\n",
        "        loss = loss_func(torch.sigmoid(output), all_target)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        \n",
        "        # BPR O 모델 학습\n",
        "        bpr_optimizer.zero_grad()\n",
        "        output = bpr_model(all_user, all_item)\n",
        "        pos_output, neg_output = torch.split(output, [len(user), len(neg_user)])\n",
        "        pos_output = torch.concat([pos_output.view(-1, 1) for _ in range(config.neg_samples)], dim = 1).view(-1)\n",
        "        loss = bpr_loss_func(pos_output, neg_output)\n",
        "\n",
        "        loss.backward()\n",
        "        bpr_optimizer.step()\n",
        "\n",
        "        bpr_train_loss += loss.item()\n",
        "\n",
        "    train_loss /= len(train_loader)\n",
        "    bpr_train_loss /= len(train_loader)\n",
        "\n",
        "    # 평가\n",
        "    non_bpr_model_hr, non_bpr_model_ndcg = metrics(model = model, test_loader = test_loader, top_k = config.top_k)\n",
        "    bpr_model_hr, bpr_model_ndcg = metrics(model = bpr_model, test_loader = test_loader, top_k = config.top_k)\n",
        "\n",
        "    if epoch == 50:\n",
        "        print(f\"[EPOCH: {epoch}]\")\n",
        "        print(f\"Non-BPR-GMF Train Loss: {train_loss:.4f}, HR: {non_bpr_model_hr:.4f}, NDCG: {non_bpr_model_ndcg:.4f}\")\n",
        "        print(f\"BPR-GMF Train Loss: {bpr_train_loss:.4f}, HR: {bpr_model_hr:.4f}, NDCG: {bpr_model_ndcg:.4f}\\n\")\n",
        "\n",
        "    result_non_bpr_hr_list.append(non_bpr_model_hr)\n",
        "    result_non_bpr_ndcg_list.append(non_bpr_model_ndcg)\n",
        "    result_hr_list.append(bpr_model_hr)\n",
        "    result_ndcg_list.append(bpr_model_ndcg)\n",
        "\n",
        "    if best_metric < non_bpr_model_hr:\n",
        "        best_metric = non_bpr_model_hr\n",
        "        torch.save(model.state_dict(), model_dir + f'Non-BPR-GMF.pt')\n",
        "\n",
        "    if bpr_best_metric < bpr_model_ndcg:\n",
        "        bpr_best_metric = bpr_model_ndcg\n",
        "        torch.save(bpr_model.state_dict(), model_dir + f'BPR-GMF.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 10회 평균 계산"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Default BPR\n",
            "HR: 0.6985692995529058\n",
            "NDCG: 0.447542335168063\n",
            "nonBPR HR: 0.6935022354694486\n",
            "onBPR NDCG: 0.44526940976394974\n"
          ]
        }
      ],
      "source": [
        "print('Default BPR')\n",
        "print('HR:',sum(result_hr_list) / len(result_hr_list))\n",
        "print('NDCG:',sum(result_ndcg_list) / len(result_ndcg_list))\n",
        "\n",
        "print('nonBPR HR:',sum(result_non_bpr_hr_list) / len(result_non_bpr_hr_list))\n",
        "print('onBPR NDCG:',sum(result_non_bpr_ndcg_list) / len(result_non_bpr_ndcg_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "Z4xvxka9Zcgd",
        "outputId": "6ccc5517-fe5e-473a-e411-ad3add28e605"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "x and y must have same first dimension, but have shapes (50,) and (0,)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[206], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m ax \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m      5\u001b[0m epochs \u001b[38;5;241m=\u001b[39m [i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, config\u001b[38;5;241m.\u001b[39mepochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)]\n\u001b[1;32m----> 7\u001b[0m \u001b[43max\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbpr_model_loss_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBPR\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m ax[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mplot(epochs, non_bpr_model_loss_list, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNon-BPR\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m ax[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\dhfgo\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:1721\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1478\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1479\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1480\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1718\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1719\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1720\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[1;32m-> 1721\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[0;32m   1722\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m   1723\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
            "File \u001b[1;32mc:\\Users\\dhfgo\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\matplotlib\\axes\\_base.py:303\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, axes, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    301\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    302\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 303\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\dhfgo\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\matplotlib\\axes\\_base.py:499\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[0;32m    496\u001b[0m     axes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[0;32m    498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m--> 499\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    500\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    503\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (50,) and (0,)"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1500x500 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots(1, 3, figsize = (15, 5))\n",
        "ax = ax.flatten()\n",
        "epochs = [i for i in range(1, config.epochs + 1)]\n",
        "\n",
        "ax[0].plot(epochs, bpr_model_loss_list, label = 'BPR')\n",
        "ax[0].plot(epochs, non_bpr_model_loss_list, label = 'Non-BPR')\n",
        "ax[0].set_title('Loss')\n",
        "ax[0].legend()\n",
        "\n",
        "ax[1].plot(epochs, bpr_model_hr_list, label = 'BPR')\n",
        "ax[1].plot(epochs, non_bpr_model_hr_list, label = 'Non-BPR')\n",
        "ax[1].set_title('HR')\n",
        "ax[1].legend()\n",
        "\n",
        "ax[2].plot(epochs, bpr_model_ndcg_list, label = 'BPR')\n",
        "ax[2].plot(epochs, non_bpr_model_ndcg_list, label = 'Non-BPR')\n",
        "ax[2].set_title('NDCG')\n",
        "ax[2].legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqvhM8p6evEM"
      },
      "source": [
        "BPR Loss를 사용하는 것이 성능, 수렴 측면에서 더 좋다는 것을 알 수 있음"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyNmpkaaKT2rUQgUVXpXXScc",
      "collapsed_sections": [],
      "include_colab_link": true,
      "mount_file_id": "18FkUoKtn4VKlZsWhkoSrENPSNDbjMG9z",
      "name": "BPR.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
